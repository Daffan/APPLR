{"section": "DQN_testbed", "seed": 43, "device": "cpu", "env": "jackal", "use_container": true, "env_config": {"world_name": "Benchmarking/train/world_0.world", "VLP16": "false", "gui": "false", "verbose": "true", "max_step": 100, "time_step": 1, "laser_clip": 2, "init_position": [-8, 0, 0], "goal_position": [54, 0, 0], "param_delta": [0.2, 0.3, 1, 2], "param_init": [0.5, 1.57, 6, 20], "param_list": ["max_vel_x", "max_vel_theta", "vx_samples", "vtheta_samples"]}, "wrapper_config": {"wrapper": "bench_marking_wrapper", "wrapper_args": {"goal_distance_reward": 2, "stuck_punishment": 0.5, "punishment_reward": -500, "reward_scale": 1}}, "training_config": {"num_actor": 100, "pre_collect": 4000, "learning_rate": 0.0005, "grad_norm_clipping": 10, "hidden_layer": [128], "cnn": true, "gamma": 0.95, "n_step": 1, "target_update_freq": 800, "prioritized_replay": true, "alpha": 0.6, "beta": 0.4, "buffer_size": 500000, "epoch": 40, "step_per_epoch": 10000, "collect_per_step": 500, "update_per_step": 500, "batch_size": 128, "exploration_ratio": 0.5}}